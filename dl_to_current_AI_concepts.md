plaintext

# ğŸš€ MODERN AI & DEEP LEARNING - From Transformers to Today's Market

> **A comprehensive guide covering the evolution from Transformers to current state-of-the-art AI technologies, including LLMs, Generative AI, RAG, Agents, MLOps, and production-ready systems used in the industry today.**

---

## Table of Contents

1. [Evolution Recap: From RNNs to Transformers](#evolution-recap-from-rnns-to-transformers)
2. [Large Language Models (LLMs)](#large-language-models-llms)
3. [BERT and Encoder-Only Models](#bert-and-encoder-only-models)
4. [GPT and Decoder-Only Models](#gpt-and-decoder-only-models)
5. [Modern LLM Architectures](#modern-llm-architectures)
6. [Fine-Tuning Techniques](#fine-tuning-techniques)
7. [Prompt Engineering](#prompt-engineering)
8. [Retrieval Augmented Generation (RAG)](#retrieval-augmented-generation-rag)
9. [Vector Databases and Embeddings](#vector-databases-and-embeddings)
10. [AI Agents and Autonomous Systems](#ai-agents-and-autonomous-systems)
11. [Generative AI](#generative-ai)
12. [Vision Transformers (ViT)](#vision-transformers-vit)
13. [Multimodal Models](#multimodal-models)
14. [MLOps and Production Systems](#mlops-and-production-systems)
15. [Model Optimization and Deployment](#model-optimization-and-deployment)
16. [Evaluation and Benchmarking](#evaluation-and-benchmarking)
17. [Safety, Alignment, and Ethics](#safety-alignment-and-ethics)
18. [Current Industry Tools and Frameworks](#current-industry-tools-and-frameworks)
19. [Future Trends](#future-trends)
20. [Quick Reference and Resources](#quick-reference-and-resources)

---

## Evolution Recap: From RNNs to Transformers

### The Journey So Far

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EVOLUTION OF SEQUENCE MODELS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  RNN (1986)                                                                 â”‚
â”‚    â”‚ Problem: Vanishing gradients, can't capture long dependencies          â”‚
â”‚    â†“                                                                        â”‚
â”‚  LSTM (1997)                                                                â”‚
â”‚    â”‚ Solution: Gates to control information flow                            â”‚
â”‚    â”‚ Problem: Still sequential, slow training                               â”‚
â”‚    â†“                                                                        â”‚
â”‚  GRU (2014)                                                                 â”‚
â”‚    â”‚ Simplified LSTM, faster but same sequential limitation                 â”‚
â”‚    â†“                                                                        â”‚
â”‚  Attention Mechanism (2014-2015)                                            â”‚
â”‚    â”‚ Allow model to focus on relevant parts                                 â”‚
â”‚    â”‚ Problem: Still uses RNNs underneath                                    â”‚
â”‚    â†“                                                                        â”‚
â”‚  Transformer (2017) - "Attention Is All You Need"                          â”‚
â”‚    â”‚ Removed RNNs entirely, parallel processing                             â”‚
â”‚    â”‚ Self-attention mechanism                                               â”‚
â”‚    â†“                                                                        â”‚
â”‚  BERT (2018) - Encoder-only, bidirectional                                  â”‚
â”‚  GPT (2018) - Decoder-only, autoregressive                                  â”‚
â”‚    â”‚                                                                        â”‚
â”‚    â†“                                                                        â”‚
â”‚  GPT-2, GPT-3, GPT-4 (2019-2023)                                           â”‚
â”‚  LLaMA, Claude, PaLM, Gemini (2023-2024)                                   â”‚
â”‚    â”‚                                                                        â”‚
â”‚    â†“                                                                        â”‚
â”‚  Modern Era: Multimodal, Agents, RAG, Fine-tuning (2024-Present)           â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Transformers Changed Everything

| Aspect | Before Transformers | After Transformers |
|--------|--------------------|--------------------|
| **Training** | Sequential (slow) | Parallel (fast) |
| **Context** | Limited by memory | Full attention to all tokens |
| **Transfer Learning** | Limited | Pre-train once, fine-tune everywhere |
| **Scalability** | Hard to scale | Scale with compute and data |
| **Multimodal** | Separate architectures | Unified architecture |

---

## Large Language Models (LLMs)

### What are LLMs?

Large Language Models are neural networks trained on massive text corpora that can understand, generate, and manipulate human language. They're typically based on the Transformer architecture and contain billions of parameters.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LLM ARCHITECTURE TYPES                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ENCODER-ONLY (BERT-style)                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Input: "The [MASK] sat on the mat"                         â”‚           â”‚
â”‚  â”‚                    â†“                                        â”‚           â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”          â”‚           â”‚
â”‚  â”‚  â”‚ The â”‚ â”‚[MSK]â”‚ â”‚ sat â”‚ â”‚ on  â”‚ â”‚ the â”‚ â”‚ mat â”‚          â”‚           â”‚
â”‚  â”‚  â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜          â”‚           â”‚
â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚           â”‚
â”‚  â”‚                    â†“ Bidirectional Attention                â”‚           â”‚
â”‚  â”‚              [Contextualized Embeddings]                    â”‚           â”‚
â”‚  â”‚                    â†“                                        â”‚           â”‚
â”‚  â”‚  Output: "cat" (fill in the mask)                          â”‚           â”‚
â”‚  â”‚                                                             â”‚           â”‚
â”‚  â”‚  Use: Classification, NER, Question Answering               â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                             â”‚
â”‚  DECODER-ONLY (GPT-style)                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Input: "The cat sat on"                                    â”‚           â”‚
â”‚  â”‚                    â†“                                        â”‚           â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                           â”‚           â”‚
â”‚  â”‚  â”‚ The â”‚â†’â”‚ cat â”‚â†’â”‚ sat â”‚â†’â”‚ on  â”‚â†’ [Predict next]           â”‚           â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                           â”‚           â”‚
â”‚  â”‚                    â†“ Causal (Left-to-Right) Attention       â”‚           â”‚
â”‚  â”‚                                                             â”‚           â”‚
â”‚  â”‚  Output: "the" â†’ "mat" â†’ "." (autoregressive generation)   â”‚           â”‚
â”‚  â”‚                                                             â”‚           â”‚
â”‚  â”‚  Use: Text Generation, Chatbots, Code Generation            â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                             â”‚
â”‚  ENCODER-DECODER (T5, BART-style)                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Input: "Translate: The cat sat on the mat"                 â”‚           â”‚
â”‚  â”‚                    â†“                                        â”‚           â”‚
â”‚  â”‚           [ENCODER] â†’ [Context Vector] â†’ [DECODER]          â”‚           â”‚
â”‚  â”‚                    â†“                                        â”‚           â”‚
â”‚  â”‚  Output: "Le chat s'est assis sur le tapis"                â”‚           â”‚
â”‚  â”‚                                                             â”‚           â”‚
â”‚  â”‚  Use: Translation, Summarization, Question Answering        â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scaling Laws

LLMs follow predictable scaling laws - performance improves with:
1. **More Parameters** (model size)
2. **More Data** (training corpus)
3. **More Compute** (training FLOPs)

```
Performance âˆ (Parameters)^Î± Ã— (Data)^Î² Ã— (Compute)^Î³

Typical values: Î± â‰ˆ 0.076, Î² â‰ˆ 0.095, Î³ â‰ˆ 0.050
```

### Major LLM Families

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MAJOR LLM FAMILIES (2024)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Family          â”‚ Organization  â”‚ Key Features                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GPT-4/4o        â”‚ OpenAI        â”‚ Multimodal, largest capabilities          â”‚
â”‚ Claude 3/3.5    â”‚ Anthropic     â”‚ Safety-focused, long context (200K)       â”‚
â”‚ Gemini          â”‚ Google        â”‚ Multimodal native, efficient              â”‚
â”‚ LLaMA 2/3       â”‚ Meta          â”‚ Open weights, research-friendly           â”‚
â”‚ Mistral/Mixtral â”‚ Mistral AI    â”‚ Efficient, MoE architecture               â”‚
â”‚ Command R       â”‚ Cohere        â”‚ Enterprise, RAG-optimized                 â”‚
â”‚ Qwen            â”‚ Alibaba       â”‚ Multilingual, code-strong                 â”‚
â”‚ DeepSeek        â”‚ DeepSeek      â”‚ Open, competitive performance             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## BERT and Encoder-Only Models

### BERT (Bidirectional Encoder Representations from Transformers)

**Released:** October 2018 by Google

**Key Innovation:** Bidirectional pre-training using Masked Language Modeling (MLM)

### How BERT Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BERT ARCHITECTURE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  PRE-TRAINING TASKS:                                                        â”‚
â”‚                                                                             â”‚
â”‚  1. Masked Language Modeling (MLM)                                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚ Input:  "The [MASK] jumped over the [MASK] dog"                 â”‚    â”‚
â”‚     â”‚ Target: "The  cat   jumped over the  lazy  dog"                 â”‚    â”‚
â”‚     â”‚                                                                 â”‚    â”‚
â”‚     â”‚ â€¢ Randomly mask 15% of tokens                                   â”‚    â”‚
â”‚     â”‚ â€¢ 80% replaced with [MASK]                                      â”‚    â”‚
â”‚     â”‚ â€¢ 10% replaced with random token                                â”‚    â”‚
â”‚     â”‚ â€¢ 10% unchanged                                                 â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  2. Next Sentence Prediction (NSP)                                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚ Input:  [CLS] Sentence A [SEP] Sentence B [SEP]                 â”‚    â”‚
â”‚     â”‚ Output: IsNext / NotNext                                        â”‚    â”‚
â”‚     â”‚                                                                 â”‚    â”‚
â”‚     â”‚ â€¢ 50% actual next sentences                                     â”‚    â”‚
â”‚     â”‚ â€¢ 50% random sentences                                          â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  INPUT REPRESENTATION:                                                      â”‚
â”‚                                                                             â”‚
â”‚     Token Embeddings:     [CLS] The  cat  sat  [SEP] It  was  ... [SEP]   â”‚
â”‚           +                                                                 â”‚
â”‚     Segment Embeddings:    E_A  E_A  E_A  E_A  E_A   E_B E_B  ... E_B     â”‚
â”‚           +                                                                 â”‚
â”‚     Position Embeddings:   P_0  P_1  P_2  P_3  P_4   P_5 P_6  ... P_n     â”‚
â”‚           =                                                                 â”‚
â”‚     Final Input            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### BERT Variants

| Model | Parameters | Key Difference |
|-------|------------|----------------|
| **BERT-Base** | 110M | 12 layers, 768 hidden, 12 heads |
| **BERT-Large** | 340M | 24 layers, 1024 hidden, 16 heads |
| **RoBERTa** | 125M-355M | Removed NSP, more data, dynamic masking |
| **ALBERT** | 12M-235M | Parameter sharing, factorized embeddings |
| **DistilBERT** | 66M | Distilled, 40% smaller, 60% faster |
| **DeBERTa** | 134M-1.5B | Disentangled attention, enhanced mask decoder |

### BERT for Downstream Tasks

```python
# Classification with BERT
from transformers import BertTokenizer, BertForSequenceClassification
import torch

# Load pre-trained model and tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Tokenize input
inputs = tokenizer("Hello, I love using transformers!", return_tensors="pt")

# Forward pass
outputs = model(**inputs)
predictions = torch.softmax(outputs.logits, dim=-1)
```

### When to Use Encoder-Only Models

| Task | Why Encoder? |
|------|--------------|
| **Text Classification** | Need full context understanding |
| **Named Entity Recognition** | Bidirectional context crucial |
| **Question Answering (Extractive)** | Find answer spans in context |
| **Semantic Similarity** | Compare sentence meanings |
| **Sentiment Analysis** | Understand overall meaning |

---

## GPT and Decoder-Only Models

### GPT (Generative Pre-trained Transformer)

**Key Innovation:** Autoregressive language modeling - predict next token given previous tokens

### GPT Evolution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GPT EVOLUTION                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  GPT-1 (2018)                                                               â”‚
â”‚  â”œâ”€â”€ 117M parameters                                                        â”‚
â”‚  â”œâ”€â”€ 12 layers                                                              â”‚
â”‚  â””â”€â”€ Proved pre-training + fine-tuning works                               â”‚
â”‚                                                                             â”‚
â”‚  GPT-2 (2019)                                                               â”‚
â”‚  â”œâ”€â”€ 1.5B parameters                                                        â”‚
â”‚  â”œâ”€â”€ "Too dangerous to release" (initially)                                 â”‚
â”‚  â””â”€â”€ Zero-shot task performance emerged                                     â”‚
â”‚                                                                             â”‚
â”‚  GPT-3 (2020)                                                               â”‚
â”‚  â”œâ”€â”€ 175B parameters                                                        â”‚
â”‚  â”œâ”€â”€ In-context learning / Few-shot learning                                â”‚
â”‚  â””â”€â”€ No fine-tuning needed for many tasks                                   â”‚
â”‚                                                                             â”‚
â”‚  GPT-3.5 / ChatGPT (2022)                                                   â”‚
â”‚  â”œâ”€â”€ RLHF (Reinforcement Learning from Human Feedback)                      â”‚
â”‚  â”œâ”€â”€ Instruction following                                                  â”‚
â”‚  â””â”€â”€ Conversational ability                                                 â”‚
â”‚                                                                             â”‚
â”‚  GPT-4 (2023)                                                               â”‚
â”‚  â”œâ”€â”€ Multimodal (text + images)                                             â”‚
â”‚  â”œâ”€â”€ Significantly improved reasoning                                       â”‚
â”‚  â””â”€â”€ Longer context (8K â†’ 32K â†’ 128K tokens)                               â”‚
â”‚                                                                             â”‚
â”‚  GPT-4o (2024)                                                              â”‚
â”‚  â”œâ”€â”€ "Omni" - native multimodal                                             â”‚
â”‚  â”œâ”€â”€ Voice, vision, text unified                                            â”‚
â”‚  â””â”€â”€ Real-time capabilities                                                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How GPT Works (Autoregressive Generation)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AUTOREGRESSIVE GENERATION                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Training Objective: Predict next token                                     â”‚
â”‚                                                                             â”‚
â”‚  P(xâ‚, xâ‚‚, ..., xâ‚™) = P(xâ‚) Ã— P(xâ‚‚|xâ‚) Ã— P(xâ‚ƒ|xâ‚,xâ‚‚) Ã— ... Ã— P(xâ‚™|xâ‚..xâ‚™â‚‹â‚)â”‚
â”‚                                                                             â”‚
â”‚  Loss = -Î£ log P(xâ‚œ | xâ‚, ..., xâ‚œâ‚‹â‚)                                        â”‚
â”‚                                                                             â”‚
â”‚  Generation Process:                                                        â”‚
â”‚                                                                             â”‚
â”‚  Input:    "The cat"                                                        â”‚
â”‚              â†“                                                              â”‚
â”‚  Step 1:  "The cat" â†’ Model â†’ P(next) â†’ "sat" (sample)                     â”‚
â”‚              â†“                                                              â”‚
â”‚  Step 2:  "The cat sat" â†’ Model â†’ P(next) â†’ "on" (sample)                  â”‚
â”‚              â†“                                                              â”‚
â”‚  Step 3:  "The cat sat on" â†’ Model â†’ P(next) â†’ "the" (sample)              â”‚
â”‚              â†“                                                              â”‚
â”‚  Step 4:  "The cat sat on the" â†’ Model â†’ P(next) â†’ "mat" (sample)          â”‚
â”‚              â†“                                                              â”‚
â”‚  Output:  "The cat sat on the mat"                                         â”‚
â”‚                                                                             â”‚
â”‚  Causal Masking (during training):                                          â”‚
â”‚                                                                             â”‚
â”‚            The  cat  sat  on                                                â”‚
â”‚     The  [  1    0    0    0  ]                                            â”‚
â”‚     cat  [  1    1    0    0  ]     1 = can attend                         â”‚
â”‚     sat  [  1    1    1    0  ]     0 = cannot attend (masked)             â”‚
â”‚     on   [  1    1    1    1  ]                                            â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Decoding Strategies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       DECODING STRATEGIES                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. GREEDY DECODING                                                         â”‚
â”‚     â€¢ Always pick highest probability token                                 â”‚
â”‚     â€¢ Fast but can be repetitive                                            â”‚
â”‚     â€¢ next_token = argmax(P(x|context))                                     â”‚
â”‚                                                                             â”‚
â”‚  2. BEAM SEARCH                                                             â”‚
â”‚     â€¢ Keep top-k sequences at each step                                     â”‚
â”‚     â€¢ More diverse but still deterministic                                  â”‚
â”‚     â€¢ beam_width = 4-10 typically                                           â”‚
â”‚                                                                             â”‚
â”‚  3. TEMPERATURE SAMPLING                                                    â”‚
â”‚     â€¢ P'(x) = softmax(logits / T)                                          â”‚
â”‚     â€¢ T < 1: More focused/deterministic                                     â”‚
â”‚     â€¢ T > 1: More random/creative                                           â”‚
â”‚     â€¢ T = 1: Original distribution                                          â”‚
â”‚                                                                             â”‚
â”‚  4. TOP-K SAMPLING                                                          â”‚
â”‚     â€¢ Only sample from top-k most likely tokens                             â”‚
â”‚     â€¢ Prevents sampling very unlikely tokens                                â”‚
â”‚     â€¢ k = 40-100 typically                                                  â”‚
â”‚                                                                             â”‚
â”‚  5. TOP-P (NUCLEUS) SAMPLING                                                â”‚
â”‚     â€¢ Sample from smallest set where cumsum(P) > p                          â”‚
â”‚     â€¢ Dynamic vocabulary size                                               â”‚
â”‚     â€¢ p = 0.9-0.95 typically                                                â”‚
â”‚                                                                             â”‚
â”‚  6. REPETITION PENALTY                                                      â”‚
â”‚     â€¢ Reduce probability of already-generated tokens                        â”‚
â”‚     â€¢ Prevents loops and repetition                                         â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation

```python
from transformers import GPT2LMHeadModel, GPT2Tokenizer

# Load model and tokenizer
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
model = GPT2LMHeadModel.from_pretrained('gpt2')

# Generate text
input_text = "The future of AI is"
input_ids = tokenizer.encode(input_text, return_tensors='pt')

# Different decoding strategies
output = model.generate(
    input_ids,
    max_length=100,
    num_return_sequences=1,
    
    # Temperature sampling
    do_sample=True,
    temperature=0.7,
    
    # Top-k and Top-p
    top_k=50,
    top_p=0.95,
    
    # Repetition penalty
    repetition_penalty=1.2,
    
    # Stopping criteria
    pad_token_id=tokenizer.eos_token_id
)

generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
print(generated_text)
```

---

## Modern LLM Architectures

### Key Innovations in Modern LLMs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODERN LLM INNOVATIONS                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. ROTARY POSITION EMBEDDINGS (RoPE)                                       â”‚
â”‚     â€¢ Used in: LLaMA, Mistral, Qwen                                        â”‚
â”‚     â€¢ Encodes position through rotation of query/key vectors               â”‚
â”‚     â€¢ Better extrapolation to longer sequences                              â”‚
â”‚     â€¢ Relative position encoding                                            â”‚
â”‚                                                                             â”‚
â”‚  2. GROUPED QUERY ATTENTION (GQA)                                           â”‚
â”‚     â€¢ Used in: LLaMA 2, Mistral                                            â”‚
â”‚     â€¢ Shares key-value heads across multiple query heads                    â”‚
â”‚     â€¢ Reduces memory and compute while maintaining quality                  â”‚
â”‚     â€¢ Middle ground between MHA and MQA                                     â”‚
â”‚                                                                             â”‚
â”‚     MHA:    Qâ‚ Qâ‚‚ Qâ‚ƒ Qâ‚„  â†â†’  Kâ‚ Kâ‚‚ Kâ‚ƒ Kâ‚„  â†â†’  Vâ‚ Vâ‚‚ Vâ‚ƒ Vâ‚„               â”‚
â”‚     GQA:    Qâ‚ Qâ‚‚ Qâ‚ƒ Qâ‚„  â†â†’  Kâ‚    Kâ‚‚     â†â†’  Vâ‚    Vâ‚‚                    â”‚
â”‚     MQA:    Qâ‚ Qâ‚‚ Qâ‚ƒ Qâ‚„  â†â†’  Kâ‚            â†â†’  Vâ‚                          â”‚
â”‚                                                                             â”‚
â”‚  3. SLIDING WINDOW ATTENTION (SWA)                                          â”‚
â”‚     â€¢ Used in: Mistral, Longformer                                         â”‚
â”‚     â€¢ Each token attends to fixed window of neighbors                       â”‚
â”‚     â€¢ Linear complexity instead of quadratic                                â”‚
â”‚     â€¢ Can still capture long-range through stacking                         â”‚
â”‚                                                                             â”‚
â”‚  4. FLASH ATTENTION                                                         â”‚
â”‚     â€¢ Memory-efficient attention computation                                â”‚
â”‚     â€¢ Avoids materializing full attention matrix                            â”‚
â”‚     â€¢ 2-4x speedup, enables longer contexts                                â”‚
â”‚                                                                             â”‚
â”‚  5. MIXTURE OF EXPERTS (MoE)                                                â”‚
â”‚     â€¢ Used in: Mixtral, GPT-4 (rumored)                                    â”‚
â”‚     â€¢ Multiple "expert" FFN layers                                          â”‚
â”‚     â€¢ Router selects top-k experts per token                                â”‚
â”‚     â€¢ More parameters, same compute                                         â”‚
â”‚                                                                             â”‚
â”‚     Input â†’ Router â†’ [Expert 1] [Expert 2] ... [Expert N] â†’ Weighted Sum   â”‚
â”‚                         â†‘                                                   â”‚
â”‚                    Only top-k activated                                     â”‚
â”‚                                                                             â”‚
â”‚  6. RING ATTENTION                                                          â”‚
â”‚     â€¢ Distributes attention across devices                                  â”‚
â”‚     â€¢ Enables million+ token contexts                                       â”‚
â”‚     â€¢ Used in: Gemini 1.5                                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LLaMA Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LLaMA ARCHITECTURE                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Key Features:                                                              â”‚
â”‚  â€¢ Pre-normalization (RMSNorm before attention and FFN)                    â”‚
â”‚  â€¢ SwiGLU activation function                                               â”‚
â”‚  â€¢ Rotary Position Embeddings (RoPE)                                        â”‚
â”‚  â€¢ No bias terms in linear layers                                           â”‚
â”‚                                                                             â”‚
â”‚  LLaMA Block:                                                               â”‚
â”‚                                                                             â”‚
â”‚     Input x                                                                 â”‚
â”‚        â”‚                                                                    â”‚
â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚        â†“                              â”‚                                    â”‚
â”‚   [RMSNorm]                           â”‚                                    â”‚
â”‚        â†“                              â”‚                                    â”‚
â”‚   [Self-Attention with RoPE]          â”‚ (Residual)                         â”‚
â”‚        â†“                              â”‚                                    â”‚
â”‚        + â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚        â”‚                                                                    â”‚
â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚        â†“                              â”‚                                    â”‚
â”‚   [RMSNorm]                           â”‚                                    â”‚
â”‚        â†“                              â”‚                                    â”‚
â”‚   [SwiGLU FFN]                        â”‚ (Residual)                         â”‚
â”‚        â†“                              â”‚                                    â”‚
â”‚        + â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚        â”‚                                                                    â”‚
â”‚     Output                                                                  â”‚
â”‚                                                                             â”‚
â”‚  SwiGLU:                                                                    â”‚
â”‚     FFN(x) = (Swish(xWâ‚) âŠ™ xWâ‚ƒ) Wâ‚‚                                        â”‚
â”‚     Swish(x) = x Ã— Ïƒ(x)                                                    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Size Comparison

| Model | Parameters | Context | Released |
|-------|-----------|---------|----------|
| GPT-3 | 175B | 4K | 2020 |
| GPT-4 | ~1.8T (MoE) | 128K | 2023 |
| Claude 3 Opus | ~200B | 200K | 2024 |
| LLaMA 2 | 7B-70B | 4K | 2023 |
| LLaMA 3 | 8B-70B | 8K | 2024 |
| Mistral 7B | 7B | 32K | 2023 |
| Mixtral 8x7B | 47B (12B active) | 32K | 2023 |
| Gemini 1.5 Pro | Unknown | 1M+ | 2024 |

---

## Fine-Tuning Techniques

### The Fine-Tuning Landscape

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FINE-TUNING APPROACHES                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  FULL FINE-TUNING                                                           â”‚
â”‚  â”œâ”€â”€ Update ALL model parameters                                            â”‚
â”‚  â”œâ”€â”€ Requires lots of GPU memory                                            â”‚
â”‚  â”œâ”€â”€ Risk of catastrophic forgetting                                        â”‚
â”‚  â””â”€â”€ Best quality but most expensive                                        â”‚
â”‚                                                                             â”‚
â”‚  PARAMETER-EFFICIENT FINE-TUNING (PEFT)                                     â”‚
â”‚  â”œâ”€â”€ Only update small subset of parameters                                 â”‚
â”‚  â”œâ”€â”€ Much less memory required                                              â”‚
â”‚  â”œâ”€â”€ Faster training                                                        â”‚
â”‚  â””â”€â”€ Multiple adapters for different tasks                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LoRA (Low-Rank Adaptation)

**Key Idea:** Instead of updating full weight matrices, add low-rank decomposition.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           LoRA                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Original: h = Wx                                                           â”‚
â”‚                                                                             â”‚
â”‚  LoRA:     h = Wx + BAx                                                     â”‚
â”‚                                                                             â”‚
â”‚  Where:                                                                     â”‚
â”‚  â€¢ W âˆˆ â„^(dÃ—d) is frozen                                                   â”‚
â”‚  â€¢ A âˆˆ â„^(rÃ—d) - down projection (r << d)                                  â”‚
â”‚  â€¢ B âˆˆ â„^(dÃ—r) - up projection                                             â”‚
â”‚  â€¢ r = rank (typically 4-64)                                                â”‚
â”‚                                                                             â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚            â”‚                                 â”‚                              â”‚
â”‚     x â”€â”€â”€â”€â†’â”‚  W (frozen, dÃ—d)               â”‚â”€â”€â”€â”€â”                         â”‚
â”‚            â”‚                                 â”‚    â”‚                         â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                         â”‚
â”‚                                                   + â”€â”€â†’ h                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                         â”‚
â”‚            â”‚                                 â”‚    â”‚                         â”‚
â”‚     x â”€â”€â”€â”€â†’â”‚  A (rÃ—d) â†’ B (dÃ—r)             â”‚â”€â”€â”€â”€â”˜                         â”‚
â”‚            â”‚  (trainable, low-rank)          â”‚                              â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                             â”‚
â”‚  Benefits:                                                                  â”‚
â”‚  â€¢ Original parameters: dÂ² = 4096Â² = 16.7M                                 â”‚
â”‚  â€¢ LoRA parameters: 2 Ã— d Ã— r = 2 Ã— 4096 Ã— 8 = 65K                        â”‚
â”‚  â€¢ 99.6% reduction in trainable parameters!                                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation with PEFT

```python
from peft import LoraConfig, get_peft_model, TaskType
from transformers import AutoModelForCausalLM, AutoTokenizer

# Load base model
model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-hf")
tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf")

# Configure LoRA
lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=8,                       # Rank
    lora_alpha=32,             # Scaling factor
    lora_dropout=0.1,          # Dropout
    target_modules=[           # Which layers to adapt
        "q_proj",
        "k_proj", 
        "v_proj",
        "o_proj",
    ],
)

# Create PEFT model
peft_model = get_peft_model(model, lora_config)

# Check trainable parameters
peft_model.print_trainable_parameters()
# Output: trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.062%
```

### QLoRA (Quantized LoRA)

**Key Innovation:** Combine 4-bit quantization with LoRA for even more efficiency.

```python
from transformers import BitsAndBytesConfig
import torch

# 4-bit quantization config
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
)

# Load quantized model
model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-2-7b-hf",
    quantization_config=bnb_config,
    device_map="auto",
)

# Then apply LoRA as before
peft_model = get_peft_model(model, lora_config)
```

### Other PEFT Methods

| Method | Description | When to Use |
|--------|-------------|-------------|
| **LoRA** | Low-rank weight updates | General fine-tuning |
| **QLoRA** | LoRA + 4-bit quantization | Limited GPU memory |
| **Prefix Tuning** | Learnable prefix tokens | Generation tasks |
| **Prompt Tuning** | Soft prompts | Simple adaptation |
| **Adapter** | Bottleneck modules | Multiple tasks |
| **IA3** | Learned vectors scale activations | Very efficient |

### Instruction Fine-Tuning

**Goal:** Teach model to follow instructions rather than just predict next token.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INSTRUCTION FINE-TUNING                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Training Data Format:                                                      â”‚
â”‚                                                                             â”‚
â”‚  {                                                                          â”‚
â”‚    "instruction": "Summarize the following article",                        â”‚
â”‚    "input": "The article text goes here...",                                â”‚
â”‚    "output": "This is the summary..."                                       â”‚
â”‚  }                                                                          â”‚
â”‚                                                                             â”‚
â”‚  Prompt Template:                                                           â”‚
â”‚                                                                             â”‚
â”‚  ### Instruction:                                                           â”‚
â”‚  {instruction}                                                              â”‚
â”‚                                                                             â”‚
â”‚  ### Input:                                                                 â”‚
â”‚  {input}                                                                    â”‚
â”‚                                                                             â”‚
â”‚  ### Response:                                                              â”‚
â”‚  {output}                                                                   â”‚
â”‚                                                                             â”‚
â”‚  Popular Datasets:                                                          â”‚
â”‚  â€¢ Alpaca (52K instructions)                                                â”‚
â”‚  â€¢ Dolly (15K instructions)                                                 â”‚
â”‚  â€¢ OpenAssistant (160K conversations)                                       â”‚
â”‚  â€¢ ShareGPT (90K conversations)                                             â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RLHF (Reinforcement Learning from Human Feedback)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              RLHF PIPELINE                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  STEP 1: Supervised Fine-Tuning (SFT)                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Base Model â”€â”€â†’ Fine-tune on demonstrations â”€â”€â†’ SFT Model       â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                             â”‚
â”‚  STEP 2: Reward Model Training                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Prompt â†’ SFT Model â†’ Multiple Responses                        â”‚       â”‚
â”‚  â”‚                           â†“                                     â”‚       â”‚
â”‚  â”‚              Human ranks responses: A > B > C > D               â”‚       â”‚
â”‚  â”‚                           â†“                                     â”‚       â”‚
â”‚  â”‚              Train Reward Model to predict rankings             â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                             â”‚
â”‚  STEP 3: PPO (Proximal Policy Optimization)                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                                                                 â”‚       â”‚
â”‚  â”‚  Prompt â†’ Policy Model â†’ Response â†’ Reward Model â†’ Score        â”‚       â”‚
â”‚  â”‚              â†‘                                       â”‚          â”‚       â”‚
â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ Update with PPO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚       â”‚
â”‚  â”‚                                                                 â”‚       â”‚
â”‚  â”‚  Objective: Maximize reward while staying close to SFT model    â”‚       â”‚
â”‚  â”‚                                                                 â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                             â”‚
â”‚  Modern Alternatives:                                                       â”‚
â”‚  â€¢ DPO (Direct Preference Optimization) - No reward model needed           â”‚
â”‚  â€¢ ORPO (Odds Ratio Preference Optimization)                               â”‚
â”‚  â€¢ KTO (Kahneman-Tversky Optimization)                                     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DPO (Direct Preference Optimization)

**Key Innovation:** Skip reward model, directly optimize from preferences.

```python
# DPO Loss (simplified)
loss = -log(Ïƒ(Î² Ã— (log Ï€(y_w|x) - log Ï€_ref(y_w|x)) 
              - Î² Ã— (log Ï€(y_l|x) - log Ï€_ref(y_l|x))))

# Where:
# y_w = preferred response
# y_l = dispreferred response
# Ï€ = policy model
# Ï€_ref = reference (SFT) model
# Î² = temperature parameter
```

---

## Prompt Engineering

### What is Prompt Engineering?

The art and science of crafting inputs to get optimal outputs from LLMs.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROMPT ENGINEERING TECHNIQUES                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. ZERO-SHOT PROMPTING                                                     â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚  Prompt: "Translate to French: Hello, how are you?"             â”‚    â”‚
â”‚     â”‚  Output: "Bonjour, comment allez-vous?"                         â”‚    â”‚
â”‚     â”‚                                                                 â”‚    â”‚
â”‚     â”‚  â€¢ No examples provided                                         â”‚    â”‚
â”‚     â”‚  â€¢ Relies on model's pre-trained knowledge                      â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  2. FEW-SHOT PROMPTING                                                      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚  Prompt:                                                        â”‚    â”‚
â”‚     â”‚  "Classify sentiment:                                           â”‚    â”‚
â”‚     â”‚   'I love this!' â†’ Positive                                    â”‚    â”‚
â”‚     â”‚   'This is terrible.' â†’ Negative                               â”‚    â”‚
â”‚     â”‚   'Amazing product!' â†’ "                                       â”‚    â”‚
â”‚     â”‚  Output: "Positive"                                            â”‚    â”‚
â”‚     â”‚                                                                 â”‚    â”‚
â”‚     â”‚  â€¢ Provide examples to guide the model                          â”‚    â”‚
â”‚     â”‚  â€¢ In-context learning                                          â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  3. CHAIN-OF-THOUGHT (CoT)                                                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚  Prompt: "Q: If John has 3 apples and buys 2 more, then gives   â”‚    â”‚
â”‚     â”‚  away 1, how many does he have?                                 â”‚    â”‚
â”‚     â”‚  Let's think step by step."                                     â”‚    â”‚
â”‚     â”‚                                                                 â”‚    â”‚
â”‚     â”‚  Output: "Step 1: John starts with 3 apples.                    â”‚    â”‚
â”‚     â”‚          Step 2: He buys 2 more: 3 + 2 = 5 apples.             â”‚    â”‚
â”‚     â”‚          Step 3: He gives away 1: 5 - 1 = 4 apples.            â”‚    â”‚
â”‚     â”‚          Answer: 4 apples"                                      â”‚    â”‚
â”‚     â”‚                                                                 â”‚    â”‚
â”‚     â”‚  â€¢ Encourages step-by-step reasoning                            â”‚    â”‚
â”‚     â”‚  â€¢ Significantly improves math/logic tasks                      â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  4. TREE OF THOUGHTS (ToT)                                                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚  â€¢ Explore multiple reasoning paths                             â”‚    â”‚
â”‚     â”‚  â€¢ Evaluate and backtrack if needed                             â”‚    â”‚
â”‚     â”‚  â€¢ Good for complex problem-solving                             â”‚    â”‚
â”‚     â”‚                                                                 â”‚    â”‚
â”‚     â”‚           Problem                                               â”‚    â”‚
â”‚     â”‚              â”‚                                                  â”‚    â”‚
â”‚     â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚    â”‚
â”‚     â”‚     â†“       â†“       â†“                                          â”‚    â”‚
â”‚     â”‚  Path A  Path B  Path C                                        â”‚    â”‚
â”‚     â”‚     â”‚       â”‚       â”‚                                          â”‚    â”‚
â”‚     â”‚  Evaluate each, continue best                                   â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  5. SELF-CONSISTENCY                                                        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚  â€¢ Sample multiple reasoning paths                              â”‚    â”‚
â”‚     â”‚  â€¢ Take majority vote on final answer                           â”‚    â”‚
â”‚     â”‚  â€¢ Reduces random errors                                        â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â”‚  6. ReAct (Reasoning + Acting)                                              â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     â”‚  Thought: I need to find the current weather in Paris.          â”‚    â”‚
â”‚     â”‚  Action: search("Paris weather today")                          â”‚    â”‚
â”‚     â”‚  Observation: [Search results...]                               â”‚    â”‚
â”‚     â”‚  Thought: The weather is 15Â°C and cloudy.                       â”‚    â”‚
â”‚     â”‚  Answer: It's currently 15Â°C and cloudy in Paris.              â”‚    â”‚
â”‚     â”‚                                                                 â”‚    â”‚
â”‚     â”‚  â€¢ Interleave reasoning with tool use                           â”‚    â”‚
â”‚     â”‚  â€¢ Foundation for AI agents                                     â”‚    â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Prompt Template Best Practices

```python
# Good prompt structure
prompt_template = """
You are a {role} expert.

Context: {context}

Task: {task}

Requirements:
- {requirement_1}
- {requirement_2}
- {requirement_3}

Format your response as:
{output_format}

Input: {input}

Output:
"""

# Example
prompt = prompt_template.format(
    role="Python programming",
    context="Building a web scraping application",
    task="Write a function to extract all links from a webpage",
    requirement_1="Use the requests and BeautifulSoup libraries",
    requirement_2="Handle errors gracefully",
    requirement_3="Return a list of URLs",
    output_format="Python code with comments",
    input="https://example.com"
)
```

### System Prompts

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SYSTEM PROMPT STRUCTURE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ROLE DEFINITION                                                            â”‚
â”‚  "You are an expert data scientist with 10 years of experience..."         â”‚
â”‚                                                                             â”‚
â”‚  BEHAVIORAL CONSTRAINTS                                                     â”‚
â”‚  "Always provide accurate information. If unsure, say so..."               â”‚
â”‚                                                                             â”‚
â”‚  OUTPUT FORMAT                                                              â”‚
â”‚  "Respond in JSON format with keys: 'answer', 'confidence', 'sources'"     â”‚
â”‚                                                                             â”‚
â”‚  EXAMPLES (optional)                                                        â”‚
â”‚  "Here's an example of how to respond:..."                                 â”‚
â”‚                                                                             â”‚
â”‚  SAFETY GUIDELINES                                                          â”‚
â”‚  "Do not provide harmful information. Refuse inappropriate requests..."    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Retrieval Augmented Generation (RAG)

### What is RAG?

RAG combines LLMs with external knowledge retrieval to provide accurate, up-to-date, and verifiable responses.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           RAG ARCHITECTURE                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Without RAG:                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  User Query â”€â”€â†’ LLM â”€â”€â†’ Response (from parametric memory)    â”‚          â”‚
â”‚  â”‚                                                               â”‚          â”‚
â”‚  â”‚  Problems:                                                    â”‚          â”‚
â”‚  â”‚  â€¢ Knowledge cutoff (outdated info)                          â”‚          â”‚
â”‚  â”‚  â€¢ Hallucinations                                            â”‚          â”‚
â”‚  â”‚  â€¢ No source verification                                    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                             â”‚
â”‚  With RAG:                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚                                                               â”‚          â”‚
â”‚  â”‚  User Query                                                   â”‚          â”‚
â”‚  â”‚      â”‚                                                        â”‚          â”‚
â”‚  â”‚      â†“                                                        â”‚          â”‚
â”‚  â”‚  [Embedding Model] â”€â”€â†’ Query Vector                          â”‚          â”‚
â”‚  â”‚      â”‚                                                        â”‚          â”‚
â”‚  â”‚      â†“                                                        â”‚          â”‚
â”‚  â”‚  [Vector Database] â”€â”€â†’ Retrieve Top-K Similar Documents      â”‚          â”‚
â”‚  â”‚      â”‚                                                        â”‚          â”‚
â”‚  â”‚      â†“                                                        â”‚          â”‚
â”‚  â”‚  [Augmented Prompt] = Query + Retrieved Context              â”‚          â”‚
â”‚  â”‚      â”‚                                                        â”‚          â”‚
â”‚  â”‚      â†“                                                        â”‚          â”‚
â”‚  â”‚  [LLM] â”€â”€â†’ Response (grounded in retrieved docs)             â”‚          â”‚
â”‚  â”‚                                                               â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RAG Pipeline Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RAG PIPELINE                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  INDEXING PHASE (Offline):                                                  â”‚
â”‚                                                                             â”‚
â”‚  Documents â”€â”€â†’ Chunking â”€â”€â†’ Embedding â”€â”€â†’ Vector Store                     â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   PDF       â”‚     â”‚  Chunk 1    â”‚     â”‚  [0.1, 0.5, â”‚                   â”‚
â”‚  â”‚   HTML      â”‚ â”€â”€â†’ â”‚  Chunk 2    â”‚ â”€â”€â†’ â”‚   ...]      â”‚ â”€â”€â†’ Vector DB    â”‚
â”‚  â”‚   TXT       â”‚     â”‚  Chunk 3    â”‚     â”‚  [0.3, 0.2, â”‚                   â”‚
â”‚  â”‚   ...       â”‚     â”‚  ...        â”‚     â”‚   ...]      â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                             â”‚
â”‚  RETRIEVAL PHASE (Online):                                                  â”‚
â”‚                                                                             â”‚
â”‚  Query â”€â”€â†’ Embed â”€â”€â†’ Search â”€â”€â†’ Retrieve â”€â”€â†’ Rerank â”€â”€â†’ Context           â”‚
â”‚                                                                             â”‚
â”‚  GENERATION PHASE (Online):                                                 â”‚
â”‚                                                                             â”‚
â”‚  Context + Query â”€â”€â†’ Prompt â”€â”€â†’ LLM â”€â”€â†’ Response                          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Chunking Strategies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CHUNKING STRATEGIES                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. FIXED-SIZE CHUNKING                                                     â”‚
â”‚     â€¢ Split by character/token count                                        â”‚
â”‚     â€¢ Simple but may break semantic units                                   â”‚
â”‚     â€¢ chunk_size=512, overlap=50                                           â”‚
â”‚                                                                             â”‚
â”‚  2. SENTENCE-BASED CHUNKING                                                 â”‚
â”‚     â€¢ Split at sentence boundaries                                          â”‚
â”‚     â€¢ Preserves complete thoughts                                           â”‚
â”‚     â€¢ Variable chunk sizes                                                  â”‚
â”‚                                                                             â”‚
â”‚  3. SEMANTIC CHUNKING                                                       â”‚
â”‚     â€¢ Use embeddings to find natural break points                           â”‚
â”‚     â€¢ Group semantically similar sentences                                  â”‚
â”‚     â€¢ Higher quality but more complex                                       â”‚
â”‚                                                                             â”‚
â”‚  4. RECURSIVE CHUNKING                                                      â”‚
â”‚     â€¢ Try different separators hierarchically                               â”‚
â”‚     â€¢ \n\n â†’ \n â†’ . â†’ space                                                â”‚
â”‚     â€¢ Balances structure and size                                           â”‚
â”‚                                                                             â”‚
â”‚  5. DOCUMENT-STRUCTURE CHUNKING                                             â”‚
â”‚     â€¢ Use headers, sections, paragraphs                                     â”‚
â”‚     â€¢ Best for structured documents                                         â”‚
â”‚     â€¢ Preserves document hierarchy                                          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation with LangChain

```python
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# 1. Load documents
loader = PyPDFLoader("document.pdf")
documents = loader.load()

# 2. Split into chunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
)
chunks = text_splitter.split_documents(documents)

# 3. Create embeddings and store in vector database
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(chunks, embeddings)

# 4. Create retriever
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 5}
)

# 5. Create RAG chain
llm = ChatOpenAI(model="gpt-4")
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",  # or "map_reduce", "refine"
    retriever=retriever,
    return_source_documents=True
)

# 6. Query
result = qa_chain({"query": "What is the main topic of this document?"})
print(result["result"])
print("Sources:", result["source_documents"])
```

### Advanced RAG Techniques

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ADVANCED RAG TECHNIQUES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. HYBRID SEARCH                                                           â”‚
â”‚     â€¢ Combine dense (embedding) + sparse (BM25) retrieval                   â”‚
â”‚     â€¢ Better coverage of keyword and semantic matches                       â”‚
â”‚     â€¢ score = Î± Ã— dense_score + (1-Î±) Ã— sparse_score                       â”‚
â”‚                                                                             â”‚
â”‚  2. RERANKING                                                               â”‚
â”‚     â€¢ Retrieve more docs, rerank with cross-encoder                         â”‚
â”‚     â€¢ Cross-encoder: Compare query-doc pairs directly                       â”‚
â”‚     â€¢ Better precision at cost of latency                                   â”‚
â”‚                                                                             â”‚
â”‚  3. QUERY TRANSFORMATION                                                    â”‚
â”‚     â€¢ HyDE: Generate hypothetical answer, embed that                        â”‚
â”‚     â€¢ Query expansion: Generate multiple query variants                     â”‚
â”‚     â€¢ Step-back prompting: Ask broader question first                       â”‚
â”‚                                                                             â”‚
â”‚  4. SELF-RAG                                                                â”‚
â”‚     â€¢ Model decides when to retrieve                                        â”‚
â”‚     â€¢ Critiques its own outputs                                             â”‚
â”‚     â€¢ More dynamic retrieval                                                â”‚
â”‚                                                                             â”‚
â”‚  5. CORRECTIVE RAG (CRAG)                                                   â”‚
â”‚     â€¢ Evaluate retrieval quality                                            â”‚
â”‚     â€¢ If low quality, trigger web search                                    â”‚
â”‚     â€¢ Self-correcting pipeline                                              â”‚
â”‚                                                                             â”‚
â”‚  6. MULTI-QUERY RAG                                                         â”‚
â”‚     â€¢ Generate multiple queries from user input                             â”‚
â”‚     â€¢ Retrieve for each, combine results                                    â”‚
â”‚     â€¢ Better recall                                                         â”‚
â”‚                                                                             â”‚
â”‚  7. PARENT DOCUMENT RETRIEVER                                               â”‚
â”‚     â€¢ Index small chunks for retrieval                                      â”‚
â”‚     â€¢ Return larger parent chunks for context                               â”‚
â”‚     â€¢ Balance precision and context                                         â”‚
â”‚                                                                             â”‚
â”‚  8. CONTEXTUAL COMPRESSION                                                  â”‚
â”‚     â€¢ Compress retrieved docs to relevant parts                             â”‚
â”‚     â€¢ Reduce noise in context                                               â”‚
â”‚     â€¢ Fit more information in context window                                â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Vector Databases and Embeddings

### Embedding Models

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      EMBEDDING MODELS                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  What are Embeddings?                                                       â”‚
â”‚  â€¢ Dense vector representations of text                                     â”‚
â”‚  â€¢ Capture semantic meaning                                                 â”‚
â”‚  â€¢ Similar meanings â†’ similar vectors                                       â”‚
â”‚                                                                             â”‚
â”‚  "king" - "man" + "woman" â‰ˆ "queen"  (classic example)                     â”‚
â”‚                                                                             â”‚
â”‚  Popular Embedding Models:                                                  â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Model           â”‚ Dimensions â”‚ Max Tokens â”‚ Notes                â”‚      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚
â”‚  â”‚ OpenAI text-    â”‚ 1536/3072  â”‚ 8191       â”‚ Best quality, paid   â”‚      â”‚
â”‚  â”‚ embedding-3     â”‚            â”‚            â”‚                      â”‚      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚
â”‚  â”‚ Cohere embed-v3 â”‚ 1024       â”‚ 512        â”‚ Multilingual         â”‚      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚
â”‚  â”‚ BGE-large       â”‚ 1024       â”‚ 512        â”‚ Open source, strong  â”‚      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚
â”‚  â”‚ E5-large        â”‚ 1024       â”‚ 512        â”‚ Microsoft, versatile â”‚      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚
â”‚  â”‚ GTE-large       â”‚ 1024       â”‚ 512        â”‚ Alibaba, efficient   â”‚      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚
â”‚  â”‚ all-MiniLM-L6   â”‚ 384        â”‚ 256        â”‚ Fast, lightweight    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Vector Similarity Metrics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SIMILARITY METRICS                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. COSINE SIMILARITY                                                       â”‚
â”‚     â€¢ Measures angle between vectors                                        â”‚
â”‚     â€¢ Range: [-1, 1] (usually [0, 1] for normalized)                       â”‚
â”‚     â€¢ Most common for text embeddings                                       â”‚
â”‚                                                                             â”‚
â”‚     cos(A, B) = (A Â· B) / (||A|| Ã— ||B||)                                  â”‚
â”‚                                                                             â”‚
â”‚  2. EUCLIDEAN DISTANCE (L2)                                                 â”‚
â”‚     â€¢ Straight-line distance                                                â”‚
â”‚     â€¢ Range: [0, âˆ)                                                        â”‚
â”‚     â€¢ Sensitive to magnitude                                                â”‚
â”‚                                                                             â”‚
â”‚     d(A, B) = âˆšÎ£(Aáµ¢ - Báµ¢)Â²                                                 â”‚
â”‚                                                                             â”‚
â”‚  3. DOT PRODUCT                                                             â”‚
â”‚     â€¢ Simple inner product                                                  â”‚
â”‚     â€¢ Faster computation                                                    â”‚
â”‚     â€¢ Range: (-âˆ, âˆ)                                                       â”‚
â”‚                                                                             â”‚
â”‚     A Â· B = Î£(Aáµ¢ Ã— Báµ¢)                                                     â”‚
â”‚                                                                             â”‚
â”‚  4. MANHATTAN DISTANCE (L1)                                                 â”‚
â”‚     â€¢ Sum of absolute differences                                           â”‚
â”‚     â€¢ More robust to outliers                                               â”‚
â”‚                                                                             â”‚
â”‚     d(A, B) = Î£|Aáµ¢ - Báµ¢|                                                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Vector Databases

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      VECTOR DATABASES                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Database        â”‚ Key Features                                     â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ Pinecone        â”‚ Fully managed, serverless, high performance      â”‚    â”‚
â”‚  â”‚                 â”‚ Great for production, easy scaling               â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ Weaviate        â”‚ Open source, GraphQL API, hybrid search          â”‚    â”‚
â”‚  â”‚                 â”‚ Good ML integrations                             â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ Milvus          â”‚ Open source, highly scalable                     â”‚    â”‚
â”‚  â”‚                 â”‚ GPU acceleration, enterprise ready               â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ Qdrant          â”‚ Open source, Rust-based, fast                    â”‚    â”‚
â”‚  â”‚                 â”‚ Good filtering, payload storage                  â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ Chroma          â”‚ Open source, embedded, developer-friendly        â”‚    â”‚
â”‚  â”‚                 â”‚ Great for prototyping and local dev              â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ FAISS           â”‚ Facebook library, very fast                      â”‚    â”‚
â”‚  â”‚                 â”‚ Not a full DB, but excellent for search          â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ pgvector        â”‚ PostgreSQL extension                             â”‚    â”‚
â”‚  â”‚                 â”‚ Use existing Postgres, simpler ops               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation Examples

```python
# Using Pinecone
import pinecone
from pinecone import Pinecone, ServerlessSpec

pc = Pinecone(api_key="your-api-key")

# Create index
pc.create_index(
    name="my-index",
    dimension=1536,
    metric="cosine",
    spec=ServerlessSpec(cloud="aws", region="us-west-2")
)

index = pc.Index("my-index")

# Upsert vectors
index.upsert(vectors=[
    {"id": "vec1", "values": [0.1, 0.2, ...], "metadata": {"text": "..."}},
    {"id": "vec2", "values": [0.3, 0.4, ...], "metadata": {"text": "..."}},
])

# Query
results = index.query(
    vector=[0.1, 0.2, ...],
    top_k=5,
    include_metadata=True
)

# Using ChromaDB (local)
import chromadb

client = chromadb.Client()
collection = client.create_collection("my_collection")

# Add documents
collection.add(
    documents=["doc1 text", "doc2 text"],
    metadatas=[{"source": "a"}, {"source": "b"}],
    ids=["id1", "id2"]
)

# Query
results = collection.query(
    query_texts=["search query"],
    n_results=5
)
```

---

## AI Agents and Autonomous Systems

### What are AI Agents?

AI agents are systems that use LLMs as the reasoning engine to autonomously plan and execute tasks, using tools and interacting with external systems.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AI AGENT ARCHITECTURE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚                         â”‚   User Query    â”‚                                 â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                         AGENT CORE                                 â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚
â”‚  â”‚  â”‚                    LLM (Brain)                               â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Understands goals                                         â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Plans actions                                             â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Reasons about observations                                â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Decides next steps                                        â”‚ â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚
â”‚  â”‚                              â”‚                                    â”‚     â”‚
â”‚  â”‚                              â†“                                    â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚
â”‚  â”‚  â”‚                    MEMORY                                    â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Short-term: Current conversation                         â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Long-term: Vector store of past interactions             â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Working: Current task state                              â”‚ â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                         TOOLS                                      â”‚     â”‚
â”‚  â”‚                                                                    â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚     â”‚
â”‚  â”‚  â”‚ Search  â”‚ â”‚  Code   â”‚ â”‚  API    â”‚ â”‚Database â”‚ â”‚  File   â”‚    â”‚     â”‚
â”‚  â”‚  â”‚ Engine  â”‚ â”‚ Executorâ”‚ â”‚  Calls  â”‚ â”‚  Query  â”‚ â”‚  System â”‚    â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚     â”‚
â”‚  â”‚                                                                    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â†“                                          â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚                         â”‚   Final Output  â”‚                                 â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Frameworks

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AGENT FRAMEWORKS                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. LANGCHAIN AGENTS                                                        â”‚
â”‚     â€¢ Flexible tool use                                                     â”‚
â”‚     â€¢ Many pre-built tools                                                  â”‚
â”‚     â€¢ ReAct, OpenAI Functions, etc.                                        â”‚
â”‚                                                                             â”‚
â”‚  2. AUTOGEN (Microsoft)                                                     â”‚
â”‚     â€¢ Multi-agent conversations                                             â”‚
â”‚     â€¢ Agent collaboration                                                   â”‚
â”‚     â€¢ Code execution                                                        â”‚
â”‚                                                                             â”‚
â”‚  3. CREWAI                                                                  â”‚
â”‚     â€¢ Role-based agents                                                     â”‚
â”‚     â€¢ Process orchestration                                                 â”‚
â”‚     â€¢ Easy to define crews                                                  â”‚
â”‚                                                                             â”‚
â”‚  4. OPENAI ASSISTANTS API                                                   â”‚
â”‚     â€¢ Managed agent infrastructure                                          â”‚
â”‚     â€¢ Built-in tools (code, retrieval)                                      â”‚
â”‚     â€¢ Stateful threads                                                      â”‚
â”‚                                                                             â”‚
â”‚  5. LLAMAINDEX AGENTS                                                       â”‚
â”‚     â€¢ Data-focused agents                                                   â”‚
â”‚     â€¢ Strong RAG integration                                                â”‚
â”‚     â€¢ Query planning                                                        â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ReAct Pattern Implementation

```python
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool
from langchain_openai import ChatOpenAI
from langchain import hub

# Define tools
def search_web(query: str) -> str:
    """Search the web for information."""
    # Implementation
    return f"Search results for: {query}"

def calculator(expression: str) -> str:
    """Evaluate mathematical expressions."""
    return str(eval(expression))

tools = [
    Tool(
        name="Search",
        func=search_web,
        description="Search the web for current information"
    ),
    Tool(
        name="Calculator",
        func=calculator,
        description="Perform mathematical calculations"
    ),
]

# Create agent
llm = ChatOpenAI(model="gpt-4")
prompt = hub.pull("hwchase17/react")
agent = create_react_agent(llm, tools, prompt)

# Create executor
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    max_iterations=10
)

# Run agent
result = agent_executor.invoke({
    "input": "What is the population of France and what is it divided by 1000?"
})
```

### Multi-Agent Systems

```python
# Using CrewAI
from crewai import Agent, Task, Crew, Process

# Define agents
researcher = Agent(
    role='Senior Research Analyst',
    goal='Uncover cutting-edge developments in AI',
    backstory='You are an expert at analyzing trends...',
    tools=[search_tool, scrape_tool],
    llm=llm
)

writer = Agent(
    role='Tech Content Writer',
    goal='Write engaging content about AI discoveries',
    backstory='You are a renowned tech writer...',
    tools=[],
    llm=llm
)

# Define tasks
research_task = Task(
    description='Research the latest AI trends...',
    expected_output='A comprehensive report...',
    agent=researcher
)

writing_task = Task(
    description='Write a blog post based on the research...',
    expected_output='A polished blog post...',
    agent=writer
)

# Create crew
crew = Crew(
    agents=[researcher, writer],
    tasks=[research_task, writing_task],
    process=Process.sequential
)

# Execute
result = crew.kickoff()
```

### Function Calling

```python
# OpenAI Function Calling
from openai import OpenAI

client = OpenAI()

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get current weather for a location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "City name"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"]
                    }
                },
                "required": ["location"]
            }
        }
    }
]

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "What's the weather in Paris?"}],
    tools=tools,
    tool_choice="auto"
)

# Check if model wants to call a function
if response.choices[0].message.tool_calls:
    tool_call = response.choices[0].message.tool_calls[0]
    function_name = tool_call.function.name
    arguments = json.loads(tool_call.function.arguments)
    
    # Execute the function
    result = get_weather(**arguments)
    
    # Send result back to model
    messages.append(response.choices[0].message)
    messages.append({
        "role": "tool",
        "tool_call_id": tool_call.id,
        "content": result
    })
    
    final_response = client.chat.completions.create(
        model="gpt-4",
        messages=messages
    )
```

---

## Generative AI

### Types of Generative AI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      GENERATIVE AI LANDSCAPE                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  TEXT GENERATION                                                            â”‚
â”‚  â”œâ”€â”€ Large Language Models (GPT-4, Claude, etc.)                           â”‚
â”‚  â”œâ”€â”€ Code Generation (Codex, GitHub Copilot)                               â”‚
â”‚  â””â”€â”€ Creative Writing (stories, poetry, scripts)                           â”‚
â”‚                                                                             â”‚
â”‚  IMAGE GENERATION                                                           â”‚
â”‚  â”œâ”€â”€ Diffusion Models (Stable Diffusion, DALL-E 3, Midjourney)            â”‚
â”‚  â”œâ”€â”€ GANs (StyleGAN, BigGAN)                                               â”‚
â”‚  â””â”€â”€ Image Editing (inpainting, outpainting)                               â”‚
â”‚                                                                             â”‚
â”‚  VIDEO GENERATION                                                           â”‚
â”‚  â”œâ”€â”€ Text-to-Video (Sora, Runway, Pika)                                    â”‚
â”‚  â”œâ”€â”€ Video Editing (frame interpolation)                                   â”‚
â”‚  â””â”€â”€ Animation                                                              â”‚
â”‚                                                                             â”‚
â”‚  AUDIO GENERATION                                                           â”‚
â”‚  â”œâ”€â”€ Text-to-Speech (ElevenLabs, Bark)                                     â”‚
â”‚  â”œâ”€â”€ Music Generation (Suno, Udio)                                         â”‚
â”‚  â””â”€â”€ Voice Cloning                                                          â”‚
â”‚                                                                             â”‚
â”‚  3D GENERATION                                                              â”‚
â”‚  â”œâ”€â”€ Text-to-3D (Point-E, Shap-E)                                          â”‚
â”‚  â””â”€â”€ NeRF (Neural Radiance Fields)                                         â”‚
â”‚                                                                             â”‚
â”‚  MULTIMODAL                                                                 â”‚
â”‚  â”œâ”€â”€ GPT-4V (text + images)                                                â”‚
â”‚  â”œâ”€â”€ Gemini (text + images + video + audio)                                â”‚
â”‚  â””â”€â”€ Any-to-Any models                                                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Diffusion Models

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DIFFUSION MODELS                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  FORWARD PROCESS (Training):                                                â”‚
â”‚  Gradually add noise to image until pure noise                              â”‚
â”‚                                                                             â”‚
â”‚  xâ‚€ â”€â”€â†’ xâ‚ â”€â”€â†’ xâ‚‚ â”€â”€â†’ ... â”€â”€â†’ xâ‚œ                                          â”‚
â”‚  Image   +noise  +noise       Pure noise                                    â”‚
â”‚                                                                             â”‚
â”‚  REVERSE PROCESS (Generation):                                              â”‚
â”‚  Learn to denoise step by step                                              â”‚
â”‚                                                                             â”‚
â”‚  xâ‚œ â”€â”€â†’ xâ‚œâ‚‹â‚ â”€â”€â†’ ... â”€â”€â†’ xâ‚ â”€â”€â†’ xâ‚€                                        â”‚
â”‚  Noise  -noise            -noise  Image                                     â”‚
â”‚                                                                             â”‚
â”‚  KEY COMPONENTS:                                                            â”‚
â”‚                                                                             â”‚
â”‚  1. U-Net: Predicts noise to remove at each step                           â”‚
â”‚  2. Text Encoder: CLIP encodes text prompts                                 â”‚
â”‚  3. VAE: Compress/decompress to latent space                               â”‚
â”‚  4. Scheduler: Controls noise addition/removal                              â”‚
â”‚                                                                             â”‚
â”‚  STABLE DIFFUSION ARCHITECTURE:                                             â”‚
â”‚                                                                             â”‚
â”‚  Text Prompt â”€â”€â†’ [CLIP Text Encoder] â”€â”€â†’ Text Embeddings                   â”‚
â”‚                                              â”‚                              â”‚
â”‚                                              â†“                              â”‚
â”‚  Random Noise â”€â”€â†’ [U-Net] â†â”€â”€ Conditioning â”€â”€â”˜                             â”‚
â”‚                      â”‚                                                      â”‚
â”‚                      â†“ (iterate T steps)                                    â”‚
â”‚               Denoised Latent                                               â”‚
â”‚                      â”‚                                                      â”‚
â”‚                      â†“                                                      â”‚
â”‚               [VAE Decoder]                                                 â”‚
â”‚                      â”‚                                                      â”‚
â”‚                      â†“                                                      â”‚
â”‚               Generated Image                                               â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation Example

```python
from diffusers import StableDiffusionPipeline
import torch

# Load model
pipe = StableDiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-1",
    torch_dtype=torch.float16
)
pipe = pipe.to("cuda")

# Generate image
prompt = "A futuristic city at sunset, cyberpunk style, highly detailed"
negative_prompt = "blurry, low quality, distorted"

image = pipe(
    prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=50,
    guidance_scale=7.5,
    width=768,
    height=768
).images[0]

image.save("generated_image.png")
```

---

## Vision Transformers (ViT)

### From CNNs to Transformers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      VISION TRANSFORMER (ViT)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Traditional CNN:                                                           â”‚
â”‚  â€¢ Local receptive fields (convolutions)                                    â”‚
â”‚  â€¢ Translation equivariance                                                 â”‚
â”‚  â€¢ Hierarchical features                                                    â”‚
â”‚                                                                             â”‚
â”‚  Vision Transformer:                                                        â”‚
â”‚  â€¢ Global attention from the start                                          â”‚
â”‚  â€¢ Treats image as sequence of patches                                      â”‚
â”‚  â€¢ Same architecture as NLP transformers                                    â”‚
â”‚                                                                             â”‚
â”‚  ViT ARCHITECTURE:                                                          â”‚
â”‚                                                                             â”‚
â”‚  Input Image (224Ã—224)                                                      â”‚
â”‚        â”‚                                                                    â”‚
â”‚        â†“ Split into patches (16Ã—16)                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ [P1] [P2] [P3] ... [P196]  (14Ã—14 = 196 patches)   â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚        â”‚                                                                    â”‚
â”‚        â†“ Flatten and project                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ [CLS] [E1] [E2] [E3] ... [E196] + Position Emb     â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚        â”‚                                                                    â”‚
â”‚        â†“ Transformer Encoder (L layers)                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ Multi-Head Self-Attention                           â”‚                   â”‚
â”‚  â”‚ MLP                                                  â”‚                   â”‚
â”‚  â”‚ Layer Norm + Residuals                              â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚        â”‚                                                                    â”‚
â”‚        â†“ Use [CLS] token                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ Classification Head                                  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚        â”‚                                                                    â”‚
â”‚        â†“                                                                    â”‚
â”‚  Class Prediction                                                           â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Modern Vision Models

| Model | Key Innovation |
|-------|----------------|
| **ViT** | First pure transformer for vision |
| **DeiT** | Data-efficient training, distillation |
| **Swin Transformer** | Shifted windows, hierarchical |
| **BEiT** | BERT-style pre-training for images |
| **MAE** | Masked autoencoder, efficient pre-training |
| **CLIP** | Contrastive image-text pre-training |
| **DINO** | Self-supervised vision transformer |
| **SAM** | Segment Anything Model |

---

## Multimodal Models

### The Multimodal Revolution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MULTIMODAL ARCHITECTURES                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  EARLY FUSION:                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Image â”€â”€â†’ [Image Encoder] â”€â”€â”                              â”‚           â”‚
â”‚  â”‚                               â”œâ”€â”€â†’ [Unified Model] â”€â”€â†’ Outputâ”‚          â”‚
â”‚  â”‚  Text  â”€â”€â†’ [Text Encoder]  â”€â”€â”˜                              â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                             â”‚
â”‚  LATE FUSION:                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Image â”€â”€â†’ [Image Model] â”€â”€â†’ Features â”€â”€â”                   â”‚           â”‚
â”‚  â”‚                                          â”œâ”€â”€â†’ Combine â”€â”€â†’ Outâ”‚          â”‚
â”‚  â”‚  Text  â”€â”€â†’ [Text Model]  â”€â”€â†’ Features â”€â”€â”˜                   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                             â”‚
â”‚  CROSS-ATTENTION (LLaVA-style):                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Image â”€â”€â†’ [Vision Encoder] â”€â”€â†’ Image Tokens                â”‚           â”‚
â”‚  â”‚                                      â”‚                       â”‚           â”‚
â”‚  â”‚                                      â†“                       â”‚           â”‚
â”‚  â”‚  Text  â”€â”€â†’ [Tokenizer] â”€â”€â†’ Text Tokens + Image Tokens       â”‚           â”‚
â”‚  â”‚                                      â”‚                       â”‚           â”‚
â”‚  â”‚                                      â†“                       â”‚           â”‚
â”‚  â”‚                               [LLM Decoder]                  â”‚           â”‚
â”‚  â”‚                                      â”‚                       â”‚           â”‚
â”‚  â”‚                                      â†“                       â”‚           â”‚
â”‚  â”‚                               Response                       â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CLIP (Contrastive Language-Image Pre-training)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CLIP                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Training:                                                                  â”‚
â”‚  â€¢ 400M image-text pairs from internet                                      â”‚
â”‚  â€¢ Contrastive learning: match images with captions                         â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚                                                             â”‚           â”‚
â”‚  â”‚    Image â”€â”€â†’ [Image Encoder] â”€â”€â†’ Image Embedding            â”‚           â”‚
â”‚  â”‚                                        â†“                    â”‚           â”‚
â”‚  â”‚                              Maximize similarity            â”‚           â”‚
â”‚  â”‚                              for matching pairs             â”‚           â”‚
â”‚  â”‚                                        â†‘                    â”‚           â”‚
â”‚  â”‚    Text  â”€â”€â†’ [Text Encoder]  â”€â”€â†’ Text Embedding             â”‚           â”‚
â”‚  â”‚                                                             â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                             â”‚
â”‚  Capabilities:                                                              â”‚
â”‚  â€¢ Zero-shot image classification                                           â”‚
â”‚  â€¢ Image-text retrieval                                                     â”‚
â”‚  â€¢ Foundation for other models (Stable Diffusion)                           â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Major Multimodal Models

| Model | Modalities | Key Features |
|-------|-----------|--------------|
| **GPT-4V** | Text, Images | Strong reasoning, OCR |
| **Gemini** | Text, Images, Video, Audio | Native multimodal |
| **Claude 3** | Text, Images | Long context, safety |
| **LLaVA** | Text, Images | Open source, efficient |
| **Qwen-VL** | Text, Images | Multilingual |
| **DALL-E 3** | Text â†’ Images | High quality generation |
| **Sora** | Text â†’ Video | Long coherent videos |

---

## MLOps and Production Systems

### MLOps Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MLOPS LIFECYCLE                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Data   â”‚ â”€â”€â†’ â”‚  Model  â”‚ â”€â”€â†’ â”‚  Model  â”‚ â”€â”€â†’ â”‚  Model  â”‚              â”‚
â”‚  â”‚Ingestionâ”‚     â”‚Training â”‚     â”‚Evaluationâ”‚     â”‚Deploymentâ”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚       â†‘                                               â”‚                    â”‚
â”‚       â”‚                                               â”‚                    â”‚
â”‚       â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                    â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚     Monitoring &        â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                 â”‚     Retraining          â”‚                                â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                                                             â”‚
â”‚  KEY COMPONENTS:                                                            â”‚
â”‚                                                                             â”‚
â”‚  â€¢ Data Versioning: DVC, Delta Lake  



king Strategies

| Strategy | Description |
|----------|-------------|
| **Fixed-Size** | Split by character/token count (chunk_size=512) |
| **Sentence-Based** | Split at sentence boundaries |
| **Semantic** | Use embeddings to find natural break points |
| **Recursive** | Try different separators hierarchically |
| **Document-Structure** | Use headers, sections, paragraphs |

### Implementation with LangChain

```python
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# 1. Load documents
loader = PyPDFLoader("document.pdf")
documents = loader.load()

# 2. Split into chunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
)
chunks = text_splitter.split_documents(documents)

# 3. Create embeddings and store in vector database
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(chunks, embeddings)

# 4. Create retriever
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# 5. Create RAG chain
llm = ChatOpenAI(model="gpt-4")
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

# 6. Query
result = qa_chain({"query": "What is the main topic?"})
print(result["result"])
```

### Advanced RAG Techniques

| Technique | Description |
|-----------|-------------|
| **Hybrid Search** | Combine dense + sparse (BM25) retrieval |
| **Reranking** | Use cross-encoder to rerank results |
| **Query Transformation** | HyDE, query expansion |
| **Self-RAG** | Model decides when to retrieve |
| **CRAG** | Evaluate and correct retrieval quality |
| **Multi-Query** | Generate multiple queries, combine results |

---

## Vector Databases and Embeddings

### Embedding Models

| Model | Dimensions | Max Tokens | Notes |
|-------|------------|------------|-------|
| OpenAI text-embedding-3 | 1536/3072 | 8191 | Best quality, paid |
| Cohere embed-v3 | 1024 | 512 | Multilingual |
| BGE-large | 1024 | 512 | Open source, strong |
| E5-large | 1024 | 512 | Microsoft, versatile |
| all-MiniLM-L6 | 384 | 256 | Fast, lightweight |

### Similarity Metrics

| Metric | Formula | Best For |
|--------|---------|----------|
| **Cosine** | (AÂ·B)/(â€–Aâ€–Ã—â€–Bâ€–) | Text embeddings |
| **Euclidean** | âˆšÎ£(Aáµ¢-Báµ¢)Â² | When magnitude matters |
| **Dot Product** | Î£(Aáµ¢Ã—Báµ¢) | Normalized vectors |

### Vector Databases

| Database | Best For |
|----------|----------|
| **Pinecone** | Managed, production, scale |
| **Weaviate** | Hybrid search, GraphQL |
| **Qdrant** | Fast, Rust-based, self-hosted |
| **Milvus** | Enterprise, GPU support |
| **Chroma** | Development, embedded |
| **pgvector** | Postgres users, simple ops |

---

## AI Agents and Autonomous Systems

### Agent Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AI AGENT ARCHITECTURE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚                         â”‚   User Query    â”‚                                 â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                         AGENT CORE                                 â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚
â”‚  â”‚  â”‚                    LLM (Brain)                               â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Understands goals                                         â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Plans actions                                             â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Reasons about observations                                â”‚ â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚
â”‚  â”‚                              â”‚                                    â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚
â”‚  â”‚  â”‚                    MEMORY                                    â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Short-term: Current conversation                         â”‚ â”‚     â”‚
â”‚  â”‚  â”‚  â€¢ Long-term: Vector store of past interactions             â”‚ â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                  â”‚                                          â”‚
â”‚                                  â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                         TOOLS                                      â”‚     â”‚
â”‚  â”‚  [Search] [Code Executor] [API Calls] [Database] [File System]    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Frameworks

| Framework | Best For |
|-----------|----------|
| **LangChain** | Complex chains, agents, RAG |
| **AutoGen** | Multi-agent collaboration |
| **CrewAI** | Role-based agents |
| **OpenAI Assistants** | Managed infrastructure |
| **LlamaIndex** | Data-focused agents |

### Function Calling Example

```python
from openai import OpenAI

client = OpenAI()

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get current weather for a location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {"type": "string", "description": "City name"},
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                },
                "required": ["location"]
            }
        }
    }
]

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "What's the weather in Paris?"}],
    tools=tools,
    tool_choice="auto"
)
```

---

## Generative AI

### Types of Generative AI

| Type | Examples | Use Cases |
|------|----------|-----------|
| **Text** | GPT-4, Claude | Chatbots, writing, code |
| **Image** | DALL-E 3, Midjourney, Stable Diffusion | Art, design, marketing |
| **Video** | Sora, Runway, Pika | Film, advertising |
| **Audio** | ElevenLabs, Suno | TTS, music |
| **3D** | Point-E, Shap-E | Gaming, VR |

### Diffusion Models

```
FORWARD PROCESS (Training):
xâ‚€ â”€â”€â†’ xâ‚ â”€â”€â†’ xâ‚‚ â”€â”€â†’ ... â”€â”€â†’ xâ‚œ
Image   +noise  +noise       Pure noise

REVERSE PROCESS (Generation):
xâ‚œ â”€â”€â†’ xâ‚œâ‚‹â‚ â”€â”€â†’ ... â”€â”€â†’ xâ‚ â”€â”€â†’ xâ‚€
Noise  -noise            -noise  Image
```

### Stable Diffusion Components

1. **U-Net**: Predicts noise to remove at each step
2. **Text Encoder**: CLIP encodes text prompts
3. **VAE**: Compress/decompress to latent space
4. **Scheduler**: Controls noise addition/removal

---

## Vision Transformers (ViT)

### ViT Architecture

```
Input Image (224Ã—224)
       â”‚
       â†“ Split into patches (16Ã—16)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [P1] [P2] [P3] ... [P196]  (14Ã—14 = 196 patches)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“ Flatten and project
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [CLS] [E1] [E2] [E3] ... [E196] + Position Emb     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“ Transformer Encoder (L layers)
       â”‚
       â†“ Use [CLS] token
       â”‚
Class Prediction
```

### Modern Vision Models

| Model | Key Innovation |
|-------|----------------|
| **ViT** | First pure transformer for vision |
| **DeiT** | Data-efficient training |
| **Swin** | Shifted windows, hierarchical |
| **CLIP** | Contrastive image-text pre-training |
| **SAM** | Segment Anything Model |

---

## Multimodal Models

### Major Multimodal Models

| Model | Modalities | Key Features |
|-------|-----------|--------------|
| **GPT-4V** | Text, Images | Strong reasoning, OCR |
| **Gemini** | Text, Images, Video, Audio | Native multimodal |
| **Claude 3** | Text, Images | Long context, safety |
| **LLaVA** | Text, Images | Open source |
| **DALL-E 3** | Text â†’ Images | High quality |
| **Sora** | Text â†’ Video | Long coherent videos |

---

## MLOps and Production Systems

### MLOps Lifecycle

```
Data Ingestion â†’ Model Training â†’ Model Evaluation â†’ Model Deployment
       â†‘                                                    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Monitoring & Retraining â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Tools

| Category | Tools |
|----------|-------|
| **Experiment Tracking** | MLflow, Weights & Biases, Neptune |
| **Model Registry** | MLflow, SageMaker, Vertex AI |
| **Orchestration** | Airflow, Kubeflow, Prefect |
| **Serving** | vLLM, TGI, Triton |
| **Monitoring** | Prometheus, Grafana, Evidently |

### FastAPI Model Serving

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class GenerationRequest(BaseModel):
    prompt: str
    max_tokens: int = 100

@app.post("/generate")
async def generate(request: GenerationRequest):
    # Model inference here
    return {"generated_text": "..."}

@app.get("/health")
async def health():
    return {"status": "healthy"}
```

---

## Model Optimization and Deployment

### Quantization

| Precision | Bits | Memory | Speed |
|-----------|------|--------|-------|
| FP32 | 32 | Baseline | Baseline |
| FP16 | 16 | 50% | ~2x |
| INT8 | 8 | 25% | ~4x |
| INT4 | 4 | 12.5% | ~8x |

### Quantization Methods

| Method | Description |
|--------|-------------|
| **PTQ** | Post-training quantization |
| **QAT** | Quantization-aware training |
| **GPTQ** | Layer-wise for LLMs |
| **AWQ** | Activation-aware weight quantization |
| **GGUF** | llama.cpp format, CPU-optimized |

### Inference Engines

| Engine | Best For |
|--------|----------|
| **vLLM** | High-throughput LLM serving |
| **TensorRT-LLM** | NVIDIA GPUs |
| **llama.cpp** | CPU inference |
| **Ollama** | Local deployment |
| **TGI** | HuggingFace production |

---

## Evaluation and Benchmarking

### LLM Benchmarks

| Benchmark | What it Measures |
|-----------|------------------|
| MMLU | Multi-task language understanding |
| HellaSwag | Commonsense reasoning |
| HumanEval | Code generation |
| GSM8K | Grade school math |
| TruthfulQA | Truthfulness |
| MT-Bench | Multi-turn conversation |

### RAG Evaluation Metrics

| Metric | Description |
|--------|-------------|
| **Faithfulness** | Answer matches context? |
| **Answer Relevancy** | Addresses question? |
| **Context Precision** | Retrieved context relevant? |
| **Groundedness** | Claims supported by context? |

---

## Safety, Alignment, and Ethics

### Key Concerns

| Concern | Mitigation |
|---------|------------|
| **Hallucinations** | RAG, grounding |
| **Harmful Content** | Content filtering, RLHF |
| **Bias** | Diverse data, audits |
| **Privacy** | Differential privacy |
| **Prompt Injection** | Input validation, guardrails |

### Alignment Techniques

- **RLHF**: Learn from human preferences
- **Constitutional AI**: Self-critique against principles
- **DPO**: Direct preference optimization
- **Red Teaming**: Adversarial testing

---

## Current Industry Tools and Frameworks

### LLM Frameworks

| Framework | Best For |
|-----------|----------|
| LangChain | Complex chains, RAG |
| LlamaIndex | Data indexing, RAG |
| Haystack | Search, QA |
| DSPy | Programmatic prompting |

### Cloud Platforms

| Platform | Key Services |
|----------|--------------|
| AWS Bedrock | Multiple LLMs, RAG |
| Azure OpenAI | GPT models, enterprise |
| Google Vertex | Gemini, PaLM |
| Hugging Face | Model hub, inference |

---

## Future Trends (2024-2025)

1. **Smaller, More Efficient Models** - Phi-3, Mistral showing small can be powerful
2. **Multimodal Everything** - Native multimodal training
3. **Longer Context** - 1M+ tokens becoming standard
4. **Better Reasoning** - Chain-of-thought improvements
5. **Autonomous Agents** - More reliable tool use
6. **On-Device AI** - Privacy-preserving local models
7. **New Architectures** - State Space Models (Mamba)

---

## Quick Reference

### Model Selection Guide

| Task | Recommended Models |
|------|-------------------|
| Chat/Assistant | GPT-4, Claude 3, Gemini |
| Code | GPT-4, Claude 3, DeepSeek Coder |
| Classification | BERT, RoBERTa, DeBERTa |
| Embeddings | OpenAI Ada, BGE, E5 |
| Image Gen | DALL-E 3, Midjourney, SD |
| Self-Hosted | LLaMA 3, Mistral, Qwen |

### Essential Libraries

```bash
# Core
pip install torch transformers datasets

# LLM Apps
pip install langchain llama-index openai

# Vector DBs
pip install chromadb pinecone-client

# Fine-tuning
pip install peft trl bitsandbytes

# Serving
pip install vllm fastapi
```

---

## Conclusion

This guide covered modern AI from Transformers to production systems:

1. **Transformers are the foundation** - Understanding attention is crucial
2. **LLMs revolutionized NLP** - GPT, Claude, LLaMA families
3. **Fine-tuning is accessible** - LoRA/QLoRA on consumer hardware
4. **RAG solves knowledge limits** - Combine retrieval with generation
5. **Agents are the future** - LLMs as reasoning engines
6. **Optimization matters** - Quantization for production
7. **Safety is essential** - Guardrails and alignment

> **"The goal is not to replace human intelligence, but to augment it."**

---

*This guide represents the state of the art as of 2024. The field evolves rapidly!*
